{
 "cells": [
  {
   "cell_type": "raw",
   "id": "201afe79-48fe-4589-b9e1-577b94888b52",
   "metadata": {},
   "source": [
    "Kavya Reddy Gondhi\n",
    "HDS 5230 - High Performance Computing\n",
    "Week 05 Dask Programming Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2813f20a-d212-413d-a021-686bbe4b85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7146392a-1fe1-461f-befe-4377b25b08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'cases': 'float64',\n",
    "    'deaths': 'float64',\n",
    "    'population': 'float64',\n",
    "    'aggregate': 'object',\n",
    "    'city': 'object',\n",
    "    'country': 'object',\n",
    "    'county': 'object',\n",
    "    'state': 'object',\n",
    "    'level': 'object'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e43f652-5d8b-4541-b33b-13d355be25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('timeseries.csv', \n",
    "                 dtype=dtypes,\n",
    "                 low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3489716e-65fe-4a05-a30e-ee0eaba9eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime\n",
    "df['date'] = dd.to_datetime(df['date'])\n",
    "\n",
    "# Filter for US states and date range\n",
    "mask = (df['country'] == 'United States') & \\\n",
    "       (df['level'] == 'state') & \\\n",
    "       (df['date'] >= '2020-01-01') & \\\n",
    "       (df['date'] <= '2021-02-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83891491-f6e1-4d8d-b88d-d2e9df3df56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed = ['state', 'date', 'cases', 'deaths', 'population']\n",
    "us_states_df = df[mask][columns_needed].compute()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3a57b05-5d4b-478b-896e-f70e9ff3d1a5",
   "metadata": {},
   "source": [
    "Parallel computation should be applied to filter the US states data (df[mask].compute()). The procedure requires a scan through extensive rows to verify boolean criterion (country = US and date range restrictions). The data processing operation fits the embarrassingly parallel classification because each independent data chunk requires no sharing of intermediate results until final integration occurs. A large dataset will benefit from distributed computing when it exceeds the memory capacity of one system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3960425a-39ea-4cac-885c-89f73b6a1687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               state  mortality_rank  per_capita_mortality\n",
      "30        New Jersey             1.0              0.001712\n",
      "32          New York             2.0              0.001280\n",
      "6        Connecticut             3.0              0.001216\n",
      "21     Massachusetts             4.0              0.001187\n",
      "41      Rhode Island             5.0              0.000903\n",
      "51  Washington, D.C.             6.0              0.000791\n",
      "18         Louisiana             7.0              0.000706\n",
      "22          Michigan             8.0              0.000623\n",
      "13          Illinois             9.0              0.000553\n",
      "20          Maryland            10.0              0.000536\n"
     ]
    }
   ],
   "source": [
    "us_states_df = us_states_df.dropna()\n",
    "\n",
    "# Calculate per-capita mortality\n",
    "state_metrics = us_states_df.groupby('state').agg({\n",
    "    'deaths': lambda x: x.iloc[-1] - x.iloc[0],  # Total deaths in period\n",
    "    'population': 'mean'  # Average population\n",
    "}).reset_index()\n",
    "\n",
    "state_metrics['per_capita_mortality'] = state_metrics['deaths'] / state_metrics['population']\n",
    "state_metrics['mortality_rank'] = state_metrics['per_capita_mortality'].rank(ascending=False)\n",
    "print(state_metrics.nsmallest(10, 'mortality_rank')[['state', 'mortality_rank', 'per_capita_mortality']])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b806c96f-eada-4330-9d5d-a6099d227513",
   "metadata": {},
   "source": [
    "The practice of parallelization provides minimal advantages during per-capita mortality calculations which involve state groupby processes followed by death rate calculations against population sizes. Because we perform groupby operations on only 50 states the cost of distribution would probably outweigh possible performance enhancements. The filtered dataset with American states represents manageable data size which makes it best handled through single-machine operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9659e7ce-3b57-4ae0-804c-0e4f501c6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states_df['month_year'] = us_states_df['date'].dt.to_period('M')\n",
    "\n",
    "# Get end of month values for cases and deaths\n",
    "end_of_month = us_states_df.groupby(['state', 'month_year']).last()[['cases', 'deaths']]\n",
    "start_of_month = us_states_df.groupby(['state', 'month_year']).first()[['cases', 'deaths']]\n",
    "\n",
    "# Calculate differences\n",
    "monthly_metrics = (end_of_month - start_of_month).reset_index()\n",
    "\n",
    "# Handle potential negative values or zero cases\n",
    "monthly_metrics['cases'] = monthly_metrics['cases'].clip(lower=1)\n",
    "monthly_metrics['deaths'] = monthly_metrics['deaths'].clip(lower=0)\n",
    "\n",
    "# Calculate CFR (Case Fatality Rate)\n",
    "monthly_metrics['CFR'] = (monthly_metrics['deaths'] / monthly_metrics['cases']) * 100\n",
    "\n",
    "cfr_matrix = monthly_metrics.pivot(index='state', \n",
    "                                 columns='month_year', \n",
    "                                 values='CFR').fillna(0)\n",
    "cfr_changes = cfr_matrix.diff(axis=1).fillna(0)\n",
    "total_cfr_change = cfr_changes.abs().sum(axis=1)\n",
    "cfr_change_ranks = total_cfr_change.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71d12a57-83e3-4f9c-9e61-28b5d90ab48b",
   "metadata": {},
   "source": [
    "Executing monthly CFR calculations becomes more efficient with parallelization although the benefits diminish as the operation progresses. There are a maximum of 700 groups from the combination of 50 states and 14 months yet parallelization across these entities would produce limited performance benefits. The system handles small memory requirements while performing uncomplicated calculations. The technology expenses from distributed processing systems would probably exceeds the advantages when working with sub-microscopic temporal information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32b61eb9-5735-4c7d-98a1-0e1575c22bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              rank\n",
      "state                             \n",
      "Rhode Island                   1.0\n",
      "United States Virgin Islands   2.0\n",
      "New Jersey                     3.0\n",
      "Montana                        4.0\n",
      "Michigan                       5.0\n",
      "Missouri                       6.0\n",
      "Pennsylvania                   7.0\n",
      "Delaware                       8.0\n",
      "Connecticut                    9.0\n",
      "New Hampshire                 10.0\n"
     ]
    }
   ],
   "source": [
    "print(cfr_change_ranks.nsmallest(10).to_frame('rank'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63117f2a-b59f-418f-8454-af2893ecb2ae",
   "metadata": {},
   "source": [
    "A parallel computing setup would not help in producing the CFR changes matrix and rankings. The operations start with arithmetic calculations on the 50Ã—14 matrix before doing ranking operations. The total number of cells remains small at 700 and the computations progress step-by-step with ranking being the most sequential operation. Since the distribution costs exceed the potential benefits the total operation time would actually become slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc2dfcf-8da0-4cc4-8fc3-e98b7035f305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
